---
firstPublishedAt: 1465747672303
latestPublishedAt: 1465747672303
slug: hydra-a-precursor-to-graphql
title: Hydra, a precursor to GraphQL
---

![Hydra (v1), 2013](https://cdn-images-1.medium.com/max/4970/1*hlN_seNJiXAsIoBZHXHqbA.png)

_This post was sparked by [Lee Byron](https://medium.com/u/d9b1a61823fa)‚Äôs excellent writeup on how several Facebook projects (such as GraphQL) came about:_

> [**Why Invest in Tools?**](https://medium.com/@leeb/why-invest-in-tools-3240ce289930)

---

While my team spent much of 2013 working on core business solutions at [HigherEducation.com](http://www.highereducation.com/), a domestic, contract software company spent over a year building and maintaining an API that made [IPEDS](http://nces.ed.gov/ipeds/) (an open database for U.S. colleges) easier for our WordPress sites to build more engaging experiences on top of.

Post-launch, we started creating experiences with the API, but quickly ran into issues that went months without resolution.

### ‚ÄúThe API can‚Äôt scale past 5 sites. We have to rewrite it.‚Äù

Some enjoy rewriting others‚Äô code (after all, _they did it wrong_, right!?), but there‚Äôs no joy to be had in delaying more important projects for something **that you paid üí∞ to be already be solved**.

#### üóë The Rewrite

Late 2013, we started from scratch, rewriting the contract company‚Äôs Ruby on Rails API & schema in **1/10th the time using Node + Express**, settling on **~75ms** response times üî•.

Soon our API (with the uninspired name _Hydra_, since we started baking other features into it) was being used across dozens of sites without any performance issues at scale. That was, until we started creating more individualized, ambitious experiences‚Ä¶

#### üìâ Snowflakes Don‚Äôt Scale

**Each project using an API is naturally unique and eventually requires different data feeds.**

Soon we were returning more data per-request _just-in-case_ a data-point was needed, since adoption exploded within weeks.

Now, consumers were starting to run queries that could take **several seconds** due to greedy data-fetches being costly to query, normalize, transform, and render to the client.

#### ü§î The Re-Rewrite

At this point, in April 2014, I was kicking around ideas that, in my mind, would solve several architectural issues:

- Introduce a Dictionary of _Terms.
  _(e.g. A school‚Äôs address would be called _school.address_).

- **Every** data-point would be _opt-in_.

- **Queries were composed & co-located **to data-points.

- The **UI & Documentation is generated **from each _Term_‚Äôs definition*.*

- _Terms_ are **warehoused in a separate DB** specific to the API for speed.

As the data came from SQL and would be fetched again with SQL, I tried out a few experiments before settling on the schema:

1. _Term_/Value store in MySQL. (_Worst_)

1. _Term_/Value store in PostgreSQL. (_Better_)

1. Each _Term_ is a table. (_Great, but eventually too many joins)_

1. Grouping like-_Terms_ into tables (e.g. _Entities_). (_Best)_

Naturally, **relational data performed best in a relational database**.

After a week of prototyping , I had a **functioning demo of a dynamic API**:

![Hydra (v2) Prototype, 2014](https://cdn-images-1.medium.com/max/2046/1*_ydk_hdleHZifVg6Eqg7DQ.gif)

#### üìñ Terms

Each term was responsible for defining:

- The _table_ and _schema_ it required for warehousing.
  (This made migrations a cinch.)

- How to fetch data for warehousing.
  (As a result, each _Term_ could be updated independently.)

- How to fetch data for the API, including referencing dependencies.

- The UI for the consumer to generate an API URL from.

- How to normalize the API response (e.g. trimming, capitalization).

For example, this is how the query, UI, and warehousing was handled for the state a school was located in:

<iframe
  width="0"
  height="0"
  src=""
  frameBorder="0"
  allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
/>

#### üëç What We Did Right

- **Performance was incredible** (_~17ms_), even when requesting most data-points. The previous rewrite could take _10 seconds_ due to the complexity of joins.

- **Making multiple queries per API call seems wrong**, but performs better than expected, especially in Node + caching.

- **Warehousing complex data structures is helpful.** This helped shave off tons of joins that we would‚Äôve had to do otherwise had we kept the data in its original schema.

- **Colocating responsibilities to the _Term_** reduces cognitive overhead. As in, managing the UI, warehousing, schema, for each term was simpler vs. having a dedicated admin, migrations folder, or similar.

- **Documentation must co-exist with the API**. Generating & maintaining API docs separately (we used [aglio](https://github.com/danielgtaylor/aglio)) made keeping changes in sync difficult. With the rewrite, the UI became much of the documentation, as it is with GraphiQL.

#### üëé What We Did Wrong

- Ignored the similarities that the path for the *Term *had to the JSON output. **GraphQL seems so obvious in retrospect**, in that it is visually similar to JSON.

- **Warehousing data is largely unnecessary** if you aggressively cache & optimize queries per _Term_. This is where [facebook/dataloader](https://github.com/facebook/dataloader) shines.

- **Validate the request first**. The response was built as queries completed, so we‚Äôd often waste 9 to find the 10th had an invalid argument provided by the user.

- **Uncaught Exceptions can cause DOS downtime**. Typically you want errors to be load and _throw new Error(‚Ä¶)_ shows up real nicely in [New Relic](https://newrelic.com/). But, one errant script can cause all instances of your app to crash before another comes back online. GraphQL correctly traps errors and makes them part of the response.

#### ‚Ä¶Two Years Later‚Ä¶

![](https://cdn-images-1.medium.com/max/500/1*VkifORfYG9rs-PTTqAq77A.png)

Sadly, we abandoned that project in favor of other initiatives that, frankly, impacted users at a much larger scale. **The tech was exciting, but the application wasn‚Äôt.**

Today, we recognize & leverage GraphQL as the architectural successor to what we needed a few years earlier: **a performant, version-less API centered around the needs of individual views**, not their aggregate.

---

Thanks for making it this far! üòç

If you‚Äôd like to discuss improving ‚ÄúDeveloper Experience‚Äù, hit me up on [Twitter](https://twitter.com/ericclemmons) or [Github](https://github.com/ericclemmons).
